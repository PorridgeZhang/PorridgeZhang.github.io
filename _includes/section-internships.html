<section id="internships">
    <h2>üßëüèª‚Äçüíª Internship</h2>

    <div class="experience-item">
        <h3>
            <span>KAUST <img src="./images/KAUST.webp" alt="KAUST" loading="lazy"></span>
            <div class="muted">Apr 2025 ‚Äì Sep 2025</div>
        </h3>
        <p>I developed ray tracing algorithm for octree map coverage computing, which helps underwater robots
            efficiently perform coral monitoring.</p>
        <p>I also built a ROS2 workspace of Crazyflie for racing drone RL and multi agent RL. This integrates drones,
            sensors, motion capture systems, controllers, and algorithms into a unified system. With well-structured
            documentation, it has now become a vital piece of laboratory infrastructure, driving subsequent research.
        </p>

        <div class='gallery-row'>
            <div class="gallery-item">
                <img src='./images/structure.webp' loading="lazy">
            </div>
            <div class="gallery-item">
                <video autoplay loop muted playsinline preload="metadata">
                    <source src='./images/flip.webm' type="video/webm">
                </video>
            </div>
            <div class="gallery-item">
                <video autoplay loop muted playsinline preload="metadata">
                    <source src="./images/3drone.webm" type="video/webm">
                </video>
            </div>
            <div class="gallery-item">
                <video autoplay loop muted playsinline preload="metadata">
                    <source src="./images/droneRL.webm" type="video/webm">
                </video>
            </div>
        </div>
    </div>

    <div class="experience-item">
        <h3>
            Cytoderm technology
            <div class="muted">Dec 2024 ‚Äì Mar 2025</div>
        </h3>
        <p>I developed unmanned intelligent production lines with AGVs and robotic arms.</p>
    </div>

    <div class="experience-item">
        <h3>
            <span>Zhipu AI X-lab <img src="./images/zhipu_logo.webp" alt="Zhipu AI" loading="lazy"></span>
            <div class="muted">Jun 2024 ‚Äì Dec 2024</div>
        </h3>
        <p>I developed the Scene Iconicity Graph to enhance robotic operations, leveraging the zero-shot capabilities of
            foundation models to improve scene understanding and reasoning. Additionally, I am leading the design of a
            mobile research robot, equipped with multiple sensors and AI computing resources, aimed at advancing
            experimentation in embodied AI.</p>
        <div class='gallery-row'>
            <div class="gallery-item">
                <img src='./images/sig.webp' loading="lazy">
            </div>
            <div class="gallery-item">
                <video autoplay loop muted playsinline preload="metadata">
                    <source src='./images/dog.webm' type="video/webm">
                </video>
            </div>
            <div class="gallery-item">
                <img src="./images/sigmap.webp" loading="lazy">
            </div>
            <div class="gallery-item">
                <img src="./images/bt.webp" loading="lazy">
            </div>
        </div>
    </div>

    <div class="experience-item">
        <h3>
            <span>Skyforce Technology <img src="./images/skyforce_logo.webp" alt="Skyforce" loading="lazy"></span>
            <div class="muted">Jul 2023 ‚Äì Dec 2023</div>
        </h3>
        <p>I interned at a startup, where I developed automatic keystone correction algorithms for projectors using both
            structured light and Time-of-Flight (TOF) technologies.</p>

        <ul>
            <li><a
                    href="https://github.com/ZhouhaoZhang/My_Project_Portfolio/blob/main/internship/auto%20keystone%20correction%20projector%20with%20camera/README.md">Auto
                    Keystone Correction with Structured Light</a>: This project focused on using local homography and
                Gray code for calibration. The correction process involved triangulating the depth of key points and
                fitting the projection plane, while an accelerometer measured the direction of gravity. The homography
                matrix was computed by correlating key points on the wall with those on the projection screen, allowing
                for reconstructing the display area. The goal was to maximize the size and sharpness of the inner
                rectangle within an arbitrary convex projection. A national invention patent for this work is pending.
            </li>

            <li><a
                    href="https://github.com/ZhouhaoZhang/My_Project_Portfolio/tree/main/internship/auto%20keystone%20correction%20projector%20with%20TOF">Auto
                    Keystone Correction Projector with TOF</a>: This project utilized the VL53L5CX multi-point TOF
                sensor to detect the projection plane. Data stability was enhanced through filtering, and robustness was
                improved using the Random Sample Consensus (RANSAC) algorithm. The projection system of the
                ultra-short-throw projector was modeled using an equivalent ideal pinhole.</li>
        </ul>

        <div class='gallery-row'>
            <div class="gallery-item">
                <img src='./images/projector.webp' loading="lazy">
            </div>
            <div class="gallery-item">
                <img src='./images/projector2.webp' loading="lazy">
            </div>
            <div class="gallery-item">
                <video autoplay loop muted playsinline preload="metadata">
                    <source src='./images/camera1.webm' type="video/webm">
                </video>
            </div>
            <div class="gallery-item">
                <video autoplay loop muted playsinline preload="metadata">
                    <source src='./images/tof.webm' type="video/webm">
                </video>
            </div>
            <div class="gallery-item">
                <img src="./images/calib.webp" loading="lazy">
            </div>
        </div>
    </div>
</section>